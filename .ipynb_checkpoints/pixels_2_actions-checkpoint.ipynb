{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations for completing the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)!  In this notebook, you will learn how to control an agent in a more challenging environment, where it can learn directly from raw pixels!  **Note that this exercise is optional!**\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "from unityagents import UnityEnvironment\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/VisualBanana.app\"`\n",
    "- **Windows** (x86): `\"path/to/VisualBanana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/VisualBanana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/VisualBanana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/VisualBanana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/VisualBanana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/VisualBanana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `VisualBanana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"VisualBanana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 0\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"VisualBanana_Windows_x86_64/VisualBanana_Windows_x86_64/Banana.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The environment state is an array of raw pixels with shape `(1, 84, 84, 3)`.  *Note that this code differs from the notebook for the project, where we are grabbing **`visual_observations`** (the raw pixels) instead of **`vector_observations`**.* A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "states length:  1\n",
      "States look like:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States have shape: (1, 84, 84, 3)\n",
      "State class:  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDmHDJySHsOETkkP+P5lTLJbgYLwxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 84, 84, 3)\n",
      "(1, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.visual_observations\n",
    "print('states length: ', len(state))\n",
    "#two_frames = np.concatenate((two_frames, state[0]), axis=0)\n",
    "#print(\"two_frames shape: \", two_frames.shape)\n",
    "print('States look like:')\n",
    "plt.imshow(np.squeeze(state))\n",
    "plt.show()\n",
    "state_size = state[0].shape\n",
    "print('States have shape:', state_size)\n",
    "print('State class: ', type(state[0]))\n",
    "state[0].squeeze().shape\n",
    "plt.imshow(state[0].squeeze()[:,:,0])\n",
    "plt.show()\n",
    "\n",
    "image_tensor = state[0]\n",
    "print(image_tensor.shape)\n",
    "\n",
    "lum_tensor = extract_luminace(image_tensor)\n",
    "print(lum_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = n_frame_state(extract_luminace(image_tensor), image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 84, 84)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: -1.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.visual_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.visual_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train DQConvN\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_luminace(image_tensor):\n",
    "    image_tensor = image_tensor.squeeze()\n",
    "    \n",
    "    #return np.moveaxis(image_tensor, -1, 0)\n",
    "    r_lum = np.multiply(image_tensor[:,:,0], 0.2126)\n",
    "    g_lum = np.multiply(image_tensor[:,:,1], 0.7152)\n",
    "    b_lum = np.multiply(image_tensor[:,:,2], 0.0722)\n",
    "    \n",
    "    lum = r_lum + g_lum + b_lum\n",
    "    \n",
    "    return np.expand_dims(lum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_frame_state(lum_tensor, new_frame, n_frames=4):\n",
    "    last_frame = np.expand_dims(lum_tensor[(lum_tensor.shape[0]-1),:,:], axis=0)\n",
    "    \n",
    "    while lum_tensor.shape[0] < n_frames:\n",
    "        lum_tensor = np.concatenate((lum_tensor, last_frame), axis=0)\n",
    "        \n",
    "    return np.concatenate((lum_tensor, extract_luminace(new_frame)), axis=0)[1:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes=1000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995, min_success=100, model_name=''):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    first_min = True                   # have we hit the min \"success\" metric yet?\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.visual_observations[0]                      # get first frame\n",
    "        state = n_frame_state(extract_luminace(state), state)        # initiate first state\n",
    "        score = 0\n",
    "        while True:\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            next_state = n_frame_state(state, env_info.visual_observations[0])   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if (np.mean(scores_window)>=min_success and first_min):\n",
    "            first_min = False\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'DConvQN_min_success.pth')\n",
    "            \n",
    "            # save results to .txt\n",
    "            f = open('results/{}.txt'.format(model_name),'w')\n",
    "            f.write('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            f.close()\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(agent.qnetwork_local.state_dict(), 'DConvQN_final.pth')\n",
    "    # save results to .txt\n",
    "    f = open('results/{}.txt'.format(model_name),'a')\n",
    "    f.write('\\n' + '\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "    f.close()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 0\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 4\n",
      "States have shape: (1, 84, 84, 3)\n"
     ]
    }
   ],
   "source": [
    "# initiate Banana Unity environment\n",
    "env = UnityEnvironment(file_name=\"VisualBanana_Windows_x86_64/VisualBanana_Windows_x86_64/Banana.exe\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# enable training and reset environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.visual_observations[0]\n",
    "#print('States look like:', state)\n",
    "state_size = len(state[0])\n",
    "print('States have shape:', state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set agent hyperparameters and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DQN agent hyperparameters\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "ConvDQN = True\n",
    "M_FRAMES = 4\n",
    "N_LAYERS = 3\n",
    "FC1 = 256\n",
    "FC2 = 128\n",
    "FC3 = 64                \n",
    "DDQN = True\n",
    "PER = False\n",
    "DUELING = False\n",
    "DISTRIBUTIONAL = False\n",
    "\n",
    "hyperams = (BUFFER_SIZE, BATCH_SIZE, GAMMA, TAU, LR, UPDATE_EVERY)\n",
    "layer_units = (N_LAYERS, FC1, FC2, FC3)\n",
    "extensions = (DDQN, PER, DUELING, DISTRIBUTIONAL)\n",
    "\n",
    "# Initialize DQN agent\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0, ConvDQN=ConvDQN, m_frames=M_FRAMES,\n",
    "              layer_units=layer_units, hyperams=hyperams, extensions=extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment interaction hyperparameters and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.04\n",
      "Episode 200\tAverage Score: -0.29\n",
      "Episode 300\tAverage Score: -0.30\n",
      "Episode 400\tAverage Score: -0.06\n",
      "Episode 500\tAverage Score: 0.271\n",
      "Episode 600\tAverage Score: 0.11\n",
      "Episode 700\tAverage Score: 0.151\n",
      "Episode 760\tAverage Score: 0.30"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5421de51358c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Train the agent and return scores from each episode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps_decay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_success\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# plot the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1c634a72c00f>\u001b[0m in \u001b[0;36mdqn\u001b[1;34m(n_episodes, max_t, eps_start, eps_end, eps_decay, min_success, model_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m                   \u001b[1;31m# get the reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m                  \u001b[1;31m# see if episode has finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl\\p1_navigation\\dqn_agent.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDDQN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl\\p1_navigation\\dqn_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, experiences, gamma, DDQN)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;31m# Get expected Q values from local model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mQ_expected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqnetwork_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\drl\\p1_navigation\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;34m\"\"\"Build a network that maps state -> action values.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\drlnd\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 301\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set training hyperparameters\n",
    "model_name = \"CDQN-32-64-64-512-noBN-1fr\"\n",
    "n_episodes=1200\n",
    "max_t=1000\n",
    "eps_start=1.0\n",
    "eps_end=0.005\n",
    "eps_decay=0.98\n",
    "min_success=13.0\n",
    "\n",
    "# Train the agent and return scores from each episode\n",
    "scores = dqn(n_episodes, max_t, eps_start, eps_end, eps_decay, min_success, model_name)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "plt.savefig('results/{}.png'.format(model_name))\n",
    "\n",
    "\n",
    "\n",
    "# Close environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch the trained agent\n",
    "\n",
    "1. After the agent has been trained and the network saved...\n",
    "2. Restart the kernel  \n",
    "3. Run the first cell (the module imports)  \n",
    "4. Then run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Banana game environment\n",
    "env = UnityEnvironment(file_name=\"VisualBanana_Windows_x86_64/VisualBanana_Windows_x86_64/Banana.exe\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "action_size = brain.vector_action_space_size\n",
    "state = env_info.visual_observations[0]            # get the current state\n",
    "state_size = len(state)\n",
    "\n",
    "# Set DQN agent hyperparameters\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "N_LAYERS = 3\n",
    "FC1 = 256\n",
    "FC2 = 128\n",
    "FC3 = 64                \n",
    "DDQN = True\n",
    "PER = False\n",
    "DUELING = False\n",
    "DISTRIBUTIONAL = False\n",
    "\n",
    "hyperams = (BUFFER_SIZE, BATCH_SIZE, GAMMA, TAU, LR, UPDATE_EVERY)\n",
    "layer_units = (N_LAYERS, FC1, FC2, FC3)\n",
    "extensions = (DDQN, PER, DUELING, DISTRIBUTIONAL)\n",
    "\n",
    "# Initialize DQN agent\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0,\n",
    "              layer_units=layer_units, hyperams=hyperams, extensions=extensions)\n",
    "\n",
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('final.pth'))\n",
    "\n",
    "           \n",
    "score = 0\n",
    "eps = 0.01\n",
    "while True:\n",
    "    action = agent.act(state, eps)\n",
    "    env_info = env.step(action)[brain_name]\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    agent.step(state, action, reward, next_state, done)\n",
    "    state = next_state\n",
    "    score += reward\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "# Close environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
